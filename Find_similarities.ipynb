{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "614301b4-d748-40da-9558-f5af87b0cfed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from os import walk, listdir\n",
    "from os.path import isfile, join\n",
    "import pickle as pk\n",
    "\n",
    "from sklearn.decomposition import PCA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "28873cc0-a346-4606-b503-e4d82f34ab10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_transform_embeds(embeds):\n",
    "    pca = PCA(n_components=2)\n",
    "    pca.fit(embeds)\n",
    "    pk.dump(pca, open(\"pca_transformer.pkl\", \"wb\"))\n",
    "\n",
    "    pcas = pca.transform(embeds)\n",
    "    np.save('unbalanced_results/tr_pcas.npy', pcas)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5e367042-faf9-40ce-89db-79754cfd8374",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_embeds(model_name, embeds, init, load = True):\n",
    "    # if load is True: load the compiled PCA model on training set,\n",
    "    # otherwise build new transformer only on test data\n",
    "    if load:\n",
    "        pca = pk.load(open(f'projection_models/{model_name}.pkl', 'rb'))\n",
    "    else:\n",
    "        pca = PCA(n_components=2)\n",
    "        pca.fit(embeds)\n",
    "    \n",
    "    #save projection model\n",
    "    pk.dump(pca, open(\"projection_models/pca_test_transformer.pkl\", \"wb\"))\n",
    "    \n",
    "    #save projected embeddings\n",
    "    pcas = pca.transform(embeds)\n",
    "    np.save(f'pca_projected_embdes/{init}_pcas.npy', pcas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "371edb50-f4f6-4c4a-bf44-f20d1f159fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load all test file names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "cfd37e08-8b11-458e-8233-1afff29b4e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_path = 'test_data'\n",
    "gfiles = []\n",
    "test_dirs = listdir(test_path)\n",
    "for tdirs in test_dirs:\n",
    "    gfiles.extend([join(test_path, tdirs, f) for f in listdir(join(test_path, tdirs))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "22363541-d224-4214-a83e-5f1af8367efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all test sets embedding and construct projection space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f7436b29-6897-4081-bb40-98586eb89b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeds = []\n",
    "for embed in gfiles:\n",
    "    embeds.append(np.load(embed))\n",
    "\n",
    "transform_embeds('', np.array(embeds), 'test_sets', load = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "2b1e6b3f-5fd6-4455-a519-eb4e8d382381",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_similarities(pca_list, fnames, fun=1):\n",
    "    t_pcas = np.load(f'pca_projected_embdes/{pca_list}.npy')\n",
    "    \n",
    "    total_distance = []\n",
    "    for t_embed, t_fname in zip(t_pcas, fnames):\n",
    "        \n",
    "        if fun ==1 :\n",
    "            dist = abs(t_embed - t_pcas).sum(axis=1)\n",
    "        if fun ==2 :\n",
    "            dist = np.square(t_embed - t_pcas).sum(axis=1)\n",
    "        if fun ==3 :\n",
    "            dist = np.sqrt(np.square(t_embed - t_pcas).sum(axis=1))\n",
    "            \n",
    "        total_distance.append(dist)\n",
    "\n",
    "    # df = pd.DataFrame(np.array(total_distance))\n",
    "    # df.columns = t_fnames\n",
    "    # df.index = t_fnames\n",
    "    # df.to_csv(\"distance.csv\", index=True, header=True)\n",
    "    \n",
    "    return np.array(total_distance)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e1a5f01-3a39-4bed-b9df-c27981e564c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "99ac8de1-71ad-4800-977a-a5f1137203ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['test_data/sanofi_v1/data_PMP_0020.npy'\n",
      " 'test_data/sanofi_v2/data_PMP_0020.npy'\n",
      " 'test_data/sanofi_v2/data_PMP_0013.npy'\n",
      " 'test_data/sanofi_v2/data_PMP_0014.npy'\n",
      " 'test_data/sanofi_v2/data_PMP_0016.npy'\n",
      " 'test_data/sanofi_v2/data_PMP_0015.npy'\n",
      " 'test_data/sanofi_v1/data_BETA_CNC_0003.npy'\n",
      " 'test_data/sanofi_v1/data_BETA_PMP_0001.npy'\n",
      " 'test_data/sanofi_v2/data_PMP_0010 bis.npy'\n",
      " 'test_data/sanofi_v2/data_PMP_0009.npy']\n",
      "[1.03947124 1.03947267 1.98496412 1.98496417 1.98496418 1.98496418\n",
      " 2.94707614 3.93913181 5.94540238 6.08913283]\n"
     ]
    }
   ],
   "source": [
    "distances = find_similarities(pca_list='test_sets_pcas', fnames=gfiles, fun=1)\n",
    "n_candidates = 10+1\n",
    "candidate = 1\n",
    "\n",
    "candidate_distances = distances[n_candidates]\n",
    "min_locs = np.argsort(candidate_distances)\n",
    "\n",
    "similars_names = np.array(gfiles)[min_locs[1:n_candidates]]\n",
    "similars_dist = candidate_distances[min_locs[1:n_candidates]]\n",
    "\n",
    "print(similars_names)\n",
    "print(similars_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "fddfcb10-e366-45d0-8fba-5bb241b673da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['test_data/sanofi_v1/data_PMP_0020.npy'\n",
      " 'test_data/sanofi_v2/data_PMP_0020.npy'\n",
      " 'test_data/sanofi_v2/data_PMP_0013.npy'\n",
      " 'test_data/sanofi_v2/data_PMP_0014.npy'\n",
      " 'test_data/sanofi_v2/data_PMP_0015.npy'\n",
      " 'test_data/sanofi_v2/data_PMP_0016.npy'\n",
      " 'test_data/sanofi_v1/data_BETA_CNC_0003.npy'\n",
      " 'test_data/sanofi_v1/data_BETA_PMP_0001.npy'\n",
      " 'test_data/sanofi_v1/data_FLT_0002 rev 1.npy'\n",
      " 'test_data/sanofi_v2/data_PMP_0048_draft.npy']\n",
      "[ 0.61703601  0.61703785  2.84942288  2.84942293  2.84942297  2.84942297\n",
      "  7.07631692 11.25967478 24.5529229  24.78779001]\n"
     ]
    }
   ],
   "source": [
    "distances = find_similarities(pca_list='test_sets_pcas', fnames=gfiles, fun=2)\n",
    "n_candidates = 10+1\n",
    "candidate = 1\n",
    "\n",
    "candidate_distances = distances[n_candidates]\n",
    "min_locs = np.argsort(candidate_distances)\n",
    "\n",
    "similars_names = np.array(gfiles)[min_locs[1:n_candidates]]\n",
    "similars_dist = candidate_distances[min_locs[1:n_candidates]]\n",
    "\n",
    "print(similars_names)\n",
    "print(similars_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4f92810-c74a-4b85-aacd-6f336c05fd96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac7667d-38b6-46f1-8114-2fb27e3e954f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
